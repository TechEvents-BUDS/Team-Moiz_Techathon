{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvckmPsyrhPIJgk1kf81aL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoHGp9-zXL07","outputId":"89541357-2ab1-4850-f0c1-4635646895aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"," * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug: * Restarting with stat\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import joblib\n","from flask import Flask, request, jsonify\n","import google.generativeai as genai\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","# API key\n","os.environ['GOOGLE_API_KEY'] = \"090078601huzaifa\"\n","\n","genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n","model = genai.GenerativeModel('gemini-pro')\n","\n","# Load and preprocess dataset\n","df = pd.read_csv('/content/drive/My Drive/kidney_disease.csv')  # Update the path to your dataset\n","\n","# Preprocessing steps (Label Encoding and handling missing values)\n","lb = LabelEncoder()\n","df['rbc'] = lb.fit_transform(df['rbc'])\n","df['pc'] = lb.fit_transform(df['pc'])\n","df['pcc'] = lb.fit_transform(df['pcc'])\n","df['ba'] = lb.fit_transform(df['ba'])\n","df['htn'] = lb.fit_transform(df['htn'])\n","df['dm'] = lb.fit_transform(df['dm'])\n","df['cad'] = lb.fit_transform(df['cad'])\n","df['appet'] = lb.fit_transform(df['appet'])\n","df['pe'] = lb.fit_transform(df['pe'])\n","df['ane'] = lb.fit_transform(df['ane'])\n","df['classification'] = lb.fit_transform(df['classification'])\n","\n","# Handle missing data and convert columns to numeric\n","df['age'] = df['age'].fillna(df['age'].mean())  # Fill missing age with mean\n","df.replace('\\t?', float('nan'), inplace=True)  # Replace '\\t?' with NaN\n","\n","columns_to_convert = ['bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot',\n","                      'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'classification']\n","for column in columns_to_convert:\n","    df[column] = pd.to_numeric(df[column], errors='coerce')\n","\n","df.dropna(inplace=True)  # Drop rows with missing values\n","\n","# Prepare features and target variable\n","X = df.drop(columns=['classification'])\n","y = df['classification']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n","\n","# Train the KNN model\n","knn = KNeighborsClassifier(n_neighbors=2)\n","knn.fit(X_train, y_train)\n","\n","# Save the trained model using joblib (so it doesn't need to be retrained every time)\n","joblib.dump(knn, 'knn_model.pkl')\n","\n","\n","# Create Flask app\n","app = Flask(__name__)\n","\n","\n","def generate_gemini_response(prompt):\n","    \"\"\"Generates a response using Gemini Pro.\"\"\"\n","    try:\n","        response = model.generate_content(prompt)\n","        return response.text\n","    except Exception as e:\n","        return f\"Error generating chatbot response: {e}\"\n","\n","\n","# Prediction endpoint\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    # Get input data from the client (C# app)\n","    data = request.get_json(force=True)\n","    input_data = np.array(data['input_data']).reshape(1, -1)  # Reshape for single prediction\n","\n","    # Load the trained model (you could also load the model outside the function to optimize)\n","    knn_model = joblib.load('knn_model.pkl')\n","\n","    # Make prediction\n","    prediction = knn_model.predict(input_data)\n","\n","    # Return the prediction as a JSON response\n","    return jsonify({'prediction': prediction.tolist()})\n","\n","\n","# Chatbot endpoint\n","@app.route('/chat', methods=['POST'])\n","def chat():\n","    # Get user message from the client\n","    data = request.get_json(force=True)\n","    user_message = data.get('message', '') # Get message from JSON or use a default\n","\n","    if not user_message:\n","        return jsonify({\"response\": \"Please provide a message.\"})\n","\n","    # Create the prompt for Gemini. You may want to inject context here (like the prediction result)\n","    prompt = (f\"You are an AI assistant that gives health information about kidney diseases. \"\n","            f\"The patient message is: {user_message}. \"\n","            \"Please respond with information about kidney diseases\"\n","            )\n","\n","    # Generate response from Gemini model\n","    gemini_response = generate_gemini_response(prompt)\n","\n","    # Respond to the user with the chatbot response\n","    return jsonify({\"response\": gemini_response})\n","\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)"]},{"cell_type":"code","source":[],"metadata":{"id":"YnimmmpSYTa0"},"execution_count":null,"outputs":[]}]}